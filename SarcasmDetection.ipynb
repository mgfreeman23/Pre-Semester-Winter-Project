{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNmRA9TTwV5OIf/+7hsgPU/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgfreeman23/Pre-Semester-Winter-Project/blob/main/SarcasmDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# News Headlines for Sarcasm Detection\n"
      ],
      "metadata": {
        "id": "ik69Nv_eGCkr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 1:**\n",
        "Import and Understand the Data"
      ],
      "metadata": {
        "id": "z05NdF7SeOOI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbD0Tz_aF4qk",
        "outputId": "a9c2c894-1f77-43b2-a459-ed62f24abd6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# import libraries and connect to google drive\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "#metric for model performance\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read in data from json file\n",
        "\n",
        "df= pd.read_json('gdrive/My Drive/CAIS++/Sarcasm_Headlines_Dataset.json', lines=True)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YZUtDvszGk0Q",
        "outputId": "20ce13cc-cbf8-4029-9fe0-9363bd99e883"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        article_link  \\\n",
              "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
              "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
              "2  https://local.theonion.com/mom-starting-to-fea...   \n",
              "3  https://politics.theonion.com/boehner-just-wan...   \n",
              "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
              "\n",
              "                                            headline  is_sarcastic  \n",
              "0  former versace store clerk sues over secret 'b...             0  \n",
              "1  the 'roseanne' revival catches up to our thorn...             0  \n",
              "2  mom starting to fear son's web series closest ...             1  \n",
              "3  boehner just wants wife to listen, not come up...             1  \n",
              "4  j.k. rowling wishes snape happy birthday in th...             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d60471c7-e1ea-4a1e-b2cc-d40cbe10d831\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_link</th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d60471c7-e1ea-4a1e-b2cc-d40cbe10d831')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d60471c7-e1ea-4a1e-b2cc-d40cbe10d831 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d60471c7-e1ea-4a1e-b2cc-d40cbe10d831');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7e3dd5e9-9236-4a35-9fc7-2b5b64a42d8a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e3dd5e9-9236-4a35-9fc7-2b5b64a42d8a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7e3dd5e9-9236-4a35-9fc7-2b5b64a42d8a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#determine number of sarcastic and non-sarcastic news articles\n",
        "\n",
        "count = df['is_sarcastic'].value_counts()[0]\n",
        "print(f\"The number of non-sarcastic/serious news is: {count}\")\n",
        "\n",
        "count = df['is_sarcastic'].value_counts()[1]\n",
        "print(f\"The number of sarcastic news is: {count}\")\n",
        "\n",
        "sns.set_style(\"darkgrid\")\n",
        "sns.countplot(df, x=\"is_sarcastic\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "0k8XRrqPIHgo",
        "outputId": "894a9e07-4020-4a97-f3c7-349e737cb7a4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of non-sarcastic/serious news is: 14985\n",
            "The number of sarcastic news is: 11724\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='is_sarcastic', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#confirm no null values in dataset\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxZcK_4fJUo6",
        "outputId": "a0d5a9e2-329d-4a25-d4d2-bfe454fb0261"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "article_link    0\n",
              "headline        0\n",
              "is_sarcastic    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 2:** Prepare to Use Data with BERT"
      ],
      "metadata": {
        "id": "JT2FtV2Betok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ensuring we can use the Colab GPU\n",
        "\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXL4uI5EKoj8",
        "outputId": "ad190bd1-bcde-4b16-a205-0911ef558a6b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install transformers\n",
        "\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVarUfxNLrA_",
        "outputId": "2fc38ab5-ffc2-4889-fe0d-c5445fbfecda"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get headlines and sarcastic labels as lists\n",
        "\n",
        "headlines = df.headline.values\n",
        "labels = df.is_sarcastic.values"
      ],
      "metadata": {
        "id": "-V061EcBPfzp"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#example of non-sarcastic headlines\n",
        "df.loc[df.is_sarcastic == 0].sample(5)[['headline', 'is_sarcastic']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "T4_sp7ZwQfpX",
        "outputId": "0dee4335-4bfb-4760-9e69-7914c8299763"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                headline  is_sarcastic\n",
              "17899         7 drawings that prove beauty is everywhere             0\n",
              "16989  california city elects dead man to office afte...             0\n",
              "15438                   why i voted for roy moore, twice             0\n",
              "11711  oklahoma governor likens striking teachers to ...             0\n",
              "15955  what the ebola virus and sen. barbara boxer ca...             0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3891849c-8da4-4dc7-a424-f20181a778b8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17899</th>\n",
              "      <td>7 drawings that prove beauty is everywhere</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16989</th>\n",
              "      <td>california city elects dead man to office afte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15438</th>\n",
              "      <td>why i voted for roy moore, twice</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11711</th>\n",
              "      <td>oklahoma governor likens striking teachers to ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15955</th>\n",
              "      <td>what the ebola virus and sen. barbara boxer ca...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3891849c-8da4-4dc7-a424-f20181a778b8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3891849c-8da4-4dc7-a424-f20181a778b8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3891849c-8da4-4dc7-a424-f20181a778b8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-892805d0-5769-4874-8ec5-80773016129d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-892805d0-5769-4874-8ec5-80773016129d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-892805d0-5769-4874-8ec5-80773016129d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example of sarcastic headlines\n",
        "df.loc[df.is_sarcastic == 1].sample(5)[['headline', 'is_sarcastic']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bKIhCrznQoEv",
        "outputId": "38898ab6-fc52-42f6-f687-df95b9e950bd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                headline  is_sarcastic\n",
              "2028   cvs now selling cheaper, cvs-brand 'people' ma...             1\n",
              "24765  huge animal jumps right fucking out in front o...             1\n",
              "11679                      conference call going awesome             1\n",
              "21266  sudden resurfacing of file called 'lyrics.doc'...             1\n",
              "1002   labor secretary letting 8 million unemployed a...             1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-66ac3987-cee8-4335-a115-d0606b05baeb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2028</th>\n",
              "      <td>cvs now selling cheaper, cvs-brand 'people' ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24765</th>\n",
              "      <td>huge animal jumps right fucking out in front o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11679</th>\n",
              "      <td>conference call going awesome</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21266</th>\n",
              "      <td>sudden resurfacing of file called 'lyrics.doc'...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002</th>\n",
              "      <td>labor secretary letting 8 million unemployed a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66ac3987-cee8-4335-a115-d0606b05baeb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-66ac3987-cee8-4335-a115-d0606b05baeb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-66ac3987-cee8-4335-a115-d0606b05baeb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7aa9750f-0f74-49b6-be1b-cdb329d8d34a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7aa9750f-0f74-49b6-be1b-cdb329d8d34a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7aa9750f-0f74-49b6-be1b-cdb329d8d34a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load BERT tokenizer\n",
        "\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyIezdiUQ1u3",
        "outputId": "09b433e3-5a12-472b-8049-7c2879675eee"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Example of tokenizing one headline with BERT\n",
        "\n",
        "# Print the original headline\n",
        "print(' Original: ', headlines[0])\n",
        "\n",
        "# Print the headline split into tokens\n",
        "print('Tokenized: ', tokenizer.tokenize(headlines[0]))\n",
        "\n",
        "# Print the headline mapped to token ids\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(headlines[0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8N0gIOL6RBLH",
        "outputId": "dafc4768-428e-49a4-e880-7bc1e6b6523b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  former versace store clerk sues over secret 'black code' for minority shoppers\n",
            "Tokenized:  ['former', 'versa', '##ce', 'store', 'clerk', 'sue', '##s', 'over', 'secret', \"'\", 'black', 'code', \"'\", 'for', 'minority', 'shop', '##pers']\n",
            "Token IDs:  [2280, 18601, 3401, 3573, 7805, 9790, 2015, 2058, 3595, 1005, 2304, 3642, 1005, 2005, 7162, 4497, 7347]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing the Data"
      ],
      "metadata": {
        "id": "QWkrSIKIf7_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Find max headline length of padding/truncating to\n",
        "\n",
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for headline in headlines:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids =  tokenizer.encode(headline, add_special_tokens = True)\n",
        "    # Update the maximum sentence length.\n",
        "    max_len =  max(max_len, len(input_ids)) #only updates the length when it gets a longer headline\n",
        "\n",
        "print('Max headline length: ', max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1JwKKfEW99E",
        "outputId": "b6e7249e-e445-43cc-9b58-55080dd8c527"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max headline length:  66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the headlines and map the tokens to their word IDs using encode_plus\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for headline in headlines:\n",
        "    #   (1) Tokenize the headline\n",
        "    #   (2) Prepend the `[CLS]` token to the start\n",
        "    #   (3) Append the `[SEP]` token to the end\n",
        "    #   (4) Map tokens to their IDs\n",
        "    #   (5) Pad or truncate the headline to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        headline,                      # Headline to encode\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = max_len,           # Pad & truncate all sentences\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask to differentiate padding from non-padding\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', headlines[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDfDiY5zYhap",
        "outputId": "234a60bb-8f5a-497c-ee2f-54c7205b14ae"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  former versace store clerk sues over secret 'black code' for minority shoppers\n",
            "Token IDs: tensor([  101,  2280, 18601,  3401,  3573,  7805,  9790,  2015,  2058,  3595,\n",
            "         1005,  2304,  3642,  1005,  2005,  7162,  4497,  7347,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 3:** Splitting into Training, Validation, and Testing Data"
      ],
      "metadata": {
        "id": "OAsRW5ajgtvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the inputs into a TensorDataset\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train/validation to testing split\n",
        "\n",
        "# Calculate the number of samples to include in training/validation set and testing set\n",
        "train_val_size = int(0.9 * len(dataset))\n",
        "test_size = len(dataset) - train_val_size\n",
        "\n",
        "# Divide the dataset randomly into training/validation and testing\n",
        "train_val_dataset, test_dataset = random_split(dataset, [train_val_size, test_size])\n",
        "\n",
        "# Repeat to split the training data into training and validation sets\n",
        "train_size = int(0.9 * len(train_val_dataset))\n",
        "val_size = len(train_val_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_val_dataset, [train_size, val_size])\n",
        "\n",
        "# Output counts\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "print('{:>5,} testing samples'.format(test_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CetkBggkZiHV",
        "outputId": "aea9484b-c6fe-46d1-96ac-c2ebbcbb25aa"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21,634 training samples\n",
            "2,404 validation samples\n",
            "2,671 testing samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using torch DataLoader class to save memory during training -> the entire dataset won't need to be loaded into memory\n",
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#specify batch size for the DataLoader\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order (RandomSampler)\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially (SequentialSampler)\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "pWjDdK6CZvl1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 4:** Fine-Tuning BERT"
      ],
      "metadata": {
        "id": "VWDhJyI0hsvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading BERT\n",
        "\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single\n",
        "# linear classification layer on top; ensure the model does NOT outputs attentions and hidden_states\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', output_attentions=False, output_hidden_states=False)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDBL1iPMZyFj",
        "outputId": "3d9b5509-124c-47d7-98fd-1f0ff13d4973"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the optimizer with recommended learning rate\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.00005)"
      ],
      "metadata": {
        "id": "80-vrqkvaSoM"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4.\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs].\n",
        "# (Note that this is not the same as the number of training samples).\n",
        "\n",
        "num_batches = train_size // batch_size;\n",
        "total_steps = num_batches*epochs;\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "89A5IJJeaY_e"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Helper Functions"
      ],
      "metadata": {
        "id": "aOQJYhRSizUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "8hMdrlhza5lQ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for nice formatting of elapsed time\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "cE5Fbhbia_t-"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Validating"
      ],
      "metadata": {
        "id": "To8epNUap34A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# To store training and validation loss, validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Total time for whole run\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 100 batches.\n",
        "        if step % 100 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # 0 the gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # token_type_ids is the same as the \"segment ids\", which\n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        result = model(b_input_ids,\n",
        "                       token_type_ids=None,\n",
        "                       attention_mask=b_input_mask,\n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the\n",
        "        # output values prior to applying an activation function like the\n",
        "        # softmax.\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0 to prevent exploding gradients\n",
        "        max_norm = 1.0\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    val_predictions , val_labels = [], []\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            result = model(b_input_ids,\n",
        "                           token_type_ids=None,\n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # For calculating MCC\n",
        "        val_predictions.append(logits)\n",
        "        val_labels.append(label_ids)\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "    # For validation MCC\n",
        "    flat_predictions = np.concatenate(val_predictions, axis=0)\n",
        "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "    flat_val_labels = np.concatenate(val_labels, axis=0)\n",
        "\n",
        "    # Report the final MCC for this validation run\n",
        "    mcc = matthews_corrcoef(flat_val_labels, flat_predictions)\n",
        "    print('Validation MCC: %.3f' % mcc)\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WiscWNUbCbw",
        "outputId": "96cf4de5-3e26-4854-ec17-4018f1119c84"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch   100  of    677.    Elapsed: 0:00:34.\n",
            "  Batch   200  of    677.    Elapsed: 0:01:09.\n",
            "  Batch   300  of    677.    Elapsed: 0:01:44.\n",
            "  Batch   400  of    677.    Elapsed: 0:02:19.\n",
            "  Batch   500  of    677.    Elapsed: 0:02:54.\n",
            "  Batch   600  of    677.    Elapsed: 0:03:29.\n",
            "\n",
            "  Average training loss: 0.26\n",
            "  Training epcoh took: 0:03:55\n",
            "\n",
            "Running Validation...\n",
            "Validation MCC: 0.852\n",
            "  Accuracy: 0.93\n",
            "  Validation Loss: 0.19\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch   100  of    677.    Elapsed: 0:00:35.\n",
            "  Batch   200  of    677.    Elapsed: 0:01:10.\n",
            "  Batch   300  of    677.    Elapsed: 0:01:45.\n",
            "  Batch   400  of    677.    Elapsed: 0:02:19.\n",
            "  Batch   500  of    677.    Elapsed: 0:02:54.\n",
            "  Batch   600  of    677.    Elapsed: 0:03:29.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Training epcoh took: 0:03:56\n",
            "\n",
            "Running Validation...\n",
            "Validation MCC: 0.837\n",
            "  Accuracy: 0.92\n",
            "  Validation Loss: 0.25\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch   100  of    677.    Elapsed: 0:00:35.\n",
            "  Batch   200  of    677.    Elapsed: 0:01:10.\n",
            "  Batch   300  of    677.    Elapsed: 0:01:44.\n",
            "  Batch   400  of    677.    Elapsed: 0:02:19.\n",
            "  Batch   500  of    677.    Elapsed: 0:02:54.\n",
            "  Batch   600  of    677.    Elapsed: 0:03:29.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epcoh took: 0:03:56\n",
            "\n",
            "Running Validation...\n",
            "Validation MCC: 0.873\n",
            "  Accuracy: 0.94\n",
            "  Validation Loss: 0.31\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:12:15 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 5:** Evaluating on Testing Data"
      ],
      "metadata": {
        "id": "fEd8c2TiqgYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating DataLoader for our Testing Set\n",
        "\n",
        "testing_dataloader = DataLoader(\n",
        "            test_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "print('Number of test sentences: {:,}\\n'.format(test_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFMq8LGjqAwj",
        "outputId": "7f43ce1e-9a8d-48a3-fe1a-a6d6967bce3a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 2,671\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(test_dataset)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict\n",
        "for batch in testing_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  # Telling the model not to compute or store gradients, saving memory and\n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids,\n",
        "                     token_type_ids=None,\n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvnVqzIvrbCd",
        "outputId": "d3fc7f8b-0c1c-4d54-f285-5ae7d87901c1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 2,671 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Determining MCC\n",
        "\n",
        "# Combine the results across all batches.\n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoZQ4mPZvdW-",
        "outputId": "9ef6fe0e-d8ac-4a35-d022-f4a96d895dff"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determining accuracy\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Accuracy: %.3f' % accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1psxWvGRwAo3",
        "outputId": "d4fcd00c-b7ac-45aa-88cf-0a3b1ca6c036"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.935\n"
          ]
        }
      ]
    }
  ]
}